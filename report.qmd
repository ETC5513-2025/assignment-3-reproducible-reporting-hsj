---
title: "Education & Career Success"
author: "Tran Dang Huy, Sia Chawla Chawla, Jiaqi Xu"

editor: source
embed-resources: true


# set report format 
format:
  pdf:
    toc: true
    theme: journal
    margin-top: 20mm
    margin-bottom: 25mm
    margin-left: 25mm
    margin-right: 25mm

# code chunk and result settings, globally, (method 1)
execute: 
  echo: false      # hide code chunk
  eval: true       # run the code
  include: true    # show output
  cache: false     
  warning: false
  message: false
  fig-align: "center"   # plot's position: left, center, or right
  fig-width: 6          # plot's width
  fig-height: 4         # plot's height
  out-width: "65%"      # % width of inserted image

# allow sectioning
number-sections: true
section-divs: true
section-depth: 3
---

```{r}
library(knitr)
library(tidyverse)
library(randomForest)
```

# Executive summary {#sec-summary}

(Maximum of 4 sentences)

# Introduction {#sec-intro}

(Maximum 10 sentences)

Graduates today face many questions about how their experiences influence their careers. Grades alone may not determine who gets the most job opportunities. This report explores which student experiences are linked to receiving more job offers?

To answer these questions, we use a dataset of 5,000 recent graduates from Kaggle. It includes information about students’ academic background, personal demographic, and career-related outcomes. Rather than testing predefined theories, this project takes an open-ended, pattern-oriented approach. The aim is to explore which types of experiences appear most consistently linked to job outcomes and personal satisfaction.

# Methodology {#sec-method}

(Maximum 300 words; Should include a figure and a table and those must be referenced in the text and have adequate captions)

This study uses an exploratory approach to investigate how students’ academic and experiential attributes may relate to early career outcomes. The dataset includes 5,000 graduate records collected from Kaggle.

```{r}
data <- read.csv("data/education_career_success.csv")
```

```{r}
# filter gender variable, and...
# convert text liked variable into categorical variable
data <- data %>%
  dplyr::filter(Gender %in% c("Male", "Female") ) %>%
  mutate(across(where(is.character), as.factor))

# convert ordinal variable to ordered factor 
data <- data %>%
  mutate(
    Career_Satisfaction = factor(Career_Satisfaction, ordered = TRUE),
    Soft_Skills_Score = factor(Soft_Skills_Score, ordered = TRUE),
    Networking_Score = factor(Networking_Score, ordered = TRUE),
    Current_Job_Level = factor(Current_Job_Level,
                               levels = c("Entry", "Mid", "Senior", "Executive"), ordered = TRUE),
    Work_Life_Balance = factor(Work_Life_Balance, order = TRUE),
  )
```

```{r}
#| label: tbl-data
#| tbl-cap: "Dataset variables and their descriptions"

data %>% glimpse()
```

We began by examining the structure of the input variables. As shown in @tbl-data, the dataset contains a mix of continuous (e.g., `SAT_Score`), ordinal (e.g., `Certifications`), and categorical (e.g., `Field_of_Study`) features, with a wide range of unique values. This diversity limits the applicability of simple linear models and supports the use of flexible methods that can accommodate mixed data types and non-linear relationships.

We also analysed the outcome variable. As visualised in @fig-outcomeskew, variable `Job_Offers` is relatively well-distributed and show minimal skewness.

```{r}
#| label: fig-outcomeskew
#| fig-cap: "Distributions of Outcome Variable"

data %>%
  dplyr::select(Job_Offers) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value") %>%
  ggplot(aes(x = Value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  facet_wrap(~ Variable, scales = "free") +
  theme_minimal() +
  labs(x = "Value", y = "Count")
```

Given that `Job_Offers` is a count variable, we select random forest model, a non-parametric model capable of capturing complex relationships without strong distributional assumptions.

# Results {#sec-result}

(Maximum 200 words. Should include either a figure or a table.)

## Associated factors for receiving job offers. {#sec-rfForImportantFactors}

```{r}

outcome_var <- "Job_Offers"

predictors <- data %>%
  dplyr::select(-Student_ID, -Career_Satisfaction, -Work_Life_Balance) %>%
  dplyr::select(-all_of(outcome_var)) %>%
  names()

form <- as.formula(paste(outcome_var, "~", paste(predictors, collapse = " + ")))

set.seed(3)
rf_model <- randomForest(form, data = data, importance = TRUE)

```

```{r}
#| label: fig-rfimportance
#| fig-cap: "Importance of Predictors for Number of Job Offers Received"

rf_imp_df <- importance(rf_model, type = 1) %>%
  as.data.frame() %>%
  rownames_to_column("Variable") %>%
  rename(Importance = `%IncMSE`) %>%  
  arrange(desc(across(where(is.numeric))))

ggplot(rf_imp_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  labs(
    x = "Predictor",
    y = "% Increase in Accuracy"
  )
```

@fig-rfimportance shows the relative importance of predictors in the random forest model. Variables such as number of complete internships and projects, SAT score, and gender were most associated with the number of job offers receiving by the student. Negative importance scores (e.g., for Age) suggest minimal or noisy contributions to model performance.

## How to get permutation importance

The permutation importance test result is the same as asking the question "How much worse does my model perform if I destroy just this one variable"

So in a simple way, using the value from random forest model, the permutation importance was calculated by randomly shuffle the value of a variable in the tree and record its out-of-bag error, then calculate the different in out-of-bag error between the permutated value and the original value in percentage. Repeat this calculating for all the variables, we now get the permutation importance table @fig-rfimportance that shows the relative importance of predictors in the random forest model.

## What permutation importance say about the effect of variable to the number of job offers that student can get

If permutated a variable cause the error to jumps up -\> that variable has large positive importance.

If permutated a variable makes no difference -\> importance of that variable ≈ 0.

If permutated a variable lowers the error instead -\> that variable has negative importance.

## Interpretation:

By looking at the @fig-rfimportance created by Jackie, we could see that:

The amount of internship and projects you complete before, your High School GPA score, your Field of Study and Networking_score are some very strong predictors on the number of job offers. This is because by permutating these variable will create a lot of errors.

Moreover, how high of the score a student can get in SAT test together with whether that student started a business, their university GPA, their certifications, their starting salary and age are some of the variable with positive importance although not as strong as the top predictors. It is interesting to see that how much GPA a student can get in their High school has a larger impact compare to their University's GPA.

On the other hand, age of the student, their soft skill and the time taken to receive the first promotion for student seem to not be significant in term of predicting job offers. We can also see that soft skill is consider as more inferior compare to networking skill which is an interesting finding since it tell us connection is a much better investment of time compare to non-technical skills for getting job offers.

In addition, student's current job level and their university ranking are consider to be bad variables and are irrelevant in predicting how much job offers a students can get.

# Ordinal Logistic regression for career satisfaction

## Association between important factors and job offers. {#sec-visualiseTrend}

```{r}
data <- data %>%
  mutate(HS_GPA_Level = cut(
    High_School_GPA,
    breaks = c(0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4),
    labels = c( "0-0.5", "0.5-1", "1-1.5", "1.5-2", "2-2.5", "2.5-3", "3-3.5", "3.5-4"),
    right = TRUE,
    ordered_result = TRUE
  ))

data_plot <- data %>%
  select(Job_Offers, Internships_Completed, HS_GPA_Level, Field_of_Study, Networking_Score, Projects_Completed) %>%
  mutate(across(-Job_Offers, as.character)) %>%    
  pivot_longer(-Job_Offers, names_to = "Variable", values_to = "Value")
```

```{r}
#| label: fig-trend
#| fig-cap: "Relationship between the most important student experiences and job offers received"
#| 
ggplot(data_plot, aes(x = factor(Value), y = Job_Offers)) +
  geom_boxplot() + 
  facet_wrap(~ Variable, scales = "free_x") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(
    title = "Relationship between Top Predictors and Job Offers",
    x = "",
    y = "Number of Job Offers Received"
  )
```

# Discussion, conclusion and recommendations {#sec-discuss}

# Reference section {#sec-ref}

(Include at least 1 reference.)
